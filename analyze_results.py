import pandas as pd
import matplotlib.pyplot as plt
import os
from datetime import datetime

# --- Configuration ---
# The Locust load-tester service saves files with this prefix in the /mnt/results/ directory
CSV_PREFIX = "test_run_1"
INPUT_DIR = "test_results"
OUTPUT_DIR = "test_results/analysis"

def load_data(file_name):
    """Loads a CSV file into a pandas DataFrame, normalizing column names."""
    file_path = os.path.join(INPUT_DIR, file_name)
    print(f"Loading data from: {file_path}")
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Required file not found: {file_path}. Did the load test run correctly?")
    
    # stats_history CSV is large, so we process it specifically
    if 'stats_history' in file_name:
        df = pd.read_csv(file_path)
        # FIX: Normalize column names (strip whitespace, convert to lowercase)
        df.columns = df.columns.str.strip().str.lower()
        
        # Convert timestamp from milliseconds to seconds, and calculate run time
        start_time = df['timestamp'].min()
        df['Run Time (s)'] = (df['timestamp'] - start_time) / 1000.0
    else:
        df = pd.read_csv(file_path)
        # Normalize column names for the requests file as well
        df.columns = df.columns.str.strip().str.lower()

    return df

def generate_graphs(history_df, requests_df):
    """Generates and saves the two required performance graphs."""
    
    # 1. Prepare for Graphing
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # Standardize plot style
    plt.style.use('seaborn-v0_8-darkgrid')
    
    # --- GRAPH 1: Throughput (RPS) vs. Time ---
    
    # Filter for the "aggregated" row using normalized lowercase name
    throughput_df = history_df[history_df['name'] == 'aggregated']
    
    # Calculate Total RPS using normalized lowercase column names
    throughput_df['Total RPS'] = throughput_df['current rps'] + throughput_df['current failures/s']
    
    plt.figure(figsize=(12, 6))
    
    # Plot Total RPS (Success + Failure)
    plt.plot(throughput_df['Run Time (s)'], throughput_df['Total RPS'], 
             label='Total Throughput (RPS)', color='#3366cc', linewidth=2)
             
    # Plot Success RPS
    plt.plot(throughput_df['Run Time (s)'], throughput_df['current rps'], 
             label='Successful RPS', color='#4CAF50', linewidth=1.5, linestyle='--')
    
    # Highlight the point where the number of users is maximum (using normalized lowercase)
    max_users = throughput_df['user count'].max()
    plt.title(f'Application Throughput Over Time (Max Users: {max_users})', fontsize=16)
    plt.xlabel('Run Time (seconds)', fontsize=14)
    plt.ylabel('Requests Per Second (RPS)', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.6)
    
    throughput_path = os.path.join(OUTPUT_DIR, f"{CSV_PREFIX}_throughput_vs_time.png")
    plt.savefig(throughput_path)
    plt.close()
    print(f"Generated Throughput vs. Time graph: {throughput_path}")
    
    
    # --- GRAPH 2: Latency (P95) vs. Concurrent Users ---
    
    # Calculate P95 latency (95th percentile response time) for each data point (using normalized lowercase)
    latency_df = history_df[history_df['name'] == 'aggregated'].copy()
    
    # We use the '95th percentile' column directly provided by Locust (now normalized to lowercase)
    p95_col = '95th percentile'
    
    plt.figure(figsize=(12, 6))
    
    plt.plot(latency_df['user count'], latency_df[p95_col], # Using normalized lowercase column name
             label='95th Percentile Latency', color='#ff6600', marker='o', markersize=4)

    plt.title(f'P95 Latency vs. Concurrent Users', fontsize=16)
    plt.xlabel('Concurrent User Count', fontsize=14)
    plt.ylabel('95th Percentile Response Time (ms)', fontsize=14)
    
    # Add a horizontal line to indicate a common acceptable SLA (e.g., 500ms)
    plt.axhline(y=500, color='r', linestyle='-', linewidth=1, alpha=0.7, label='500ms SLA Target')
    
    plt.legend()
    plt.grid(True, alpha=0.6)
    
    latency_path = os.path.join(OUTPUT_DIR, f"{CSV_PREFIX}_latency_vs_users.png")
    plt.savefig(latency_path)
    plt.close()
    print(f"Generated P95 Latency vs. Users graph: {latency_path}")


def main():
    """Main function to run the analysis."""
    print(f"Starting analysis of load test data...")
    
    try:
        # Load the two key files generated by Locust
        history_df = load_data(f"{CSV_PREFIX}_stats_history.csv")
        requests_df = load_data(f"{CSV_PREFIX}_requests.csv")
        
        # Generate the required graphs
        generate_graphs(history_df, requests_df)
        
        print("\nAnalysis Complete! Graphs are saved in the 'test_results/analysis' directory.")

    except FileNotFoundError as e:
        print(f"\n[ERROR] Analysis failed: {e}")
        print("Please ensure you successfully ran 'docker-compose up' and that CSV files were generated.")
    except Exception as e:
        # If an error still occurs, we'll try to provide more debug info by printing the columns
        print(f"\n[ERROR] An unexpected error occurred during analysis: {e}")
        try:
             # This block will run only if the error happened before or within generate_graphs
             if 'history_df' in locals():
                 print(f"History DF Columns: {history_df.columns.tolist()}")
        except:
             pass

if __name__ == "__main__":
    # Wait briefly for filesystems to sync after the load test container exits
    import time
    time.sleep(5)
    main()
